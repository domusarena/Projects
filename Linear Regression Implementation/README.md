
# Linear Regression Implementation in Python

This small project is a personal implementation of a univariate
linear regression algorithm using squared error loss. The library
use is limited to only Numpy and Pandas (Matplotlib is used only for
visualisation). 

It is inspired by an implementation in Stanford's Machine Learning course 
found on Coursera but adapted to Python from Octave. 

Since, I enjoy learning about the mathematical and statistical 
foundations of machine learning algorithms, this was a fun project
to also enhance my ability using Numpy matrices through vectorisation
of relevant formulae.

I used gradient descent to optimise the loss function of
my algorithm, since this type of method can be generalised to
other machine learning implementations. An explanation of my gradient
descent code has been provided above. 


